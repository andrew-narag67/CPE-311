{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercise Part 4:\n",
        "\n",
        "Using the meteorite data from the Meteorite_Landings.csv file, create a pivot table that shows both the number of meteorites and the 95th percentile of meteorite mass for those that were found versus observed falling per year from 2005 through 2009 (inclusive). Hint: Be sure to convert the year column to a number as we did in the previous exercise.\n",
        "Using the meteorite data from the Meteorite_Landings.csv file, compare summary statistics of the mass column for the meteorites that were found versus observed falling."
      ],
      "metadata": {
        "id": "o22qwKpDPQc3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RpElxKwMRAO",
        "outputId": "76921a61-beba-476e-95f6-c3cea42e4be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNwZ7nykQS2n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Foldah/Meteorite_Landings.csv')\n",
        "\n",
        "data['year'] = pd.to_datetime(data['year'], errors='coerce').dt.year\n",
        "data['mass (g)'] = pd.to_numeric(data['mass (g)'], errors='coerce')\n",
        "\n",
        "filtered_data = data[(data['year'] >= 2005) & (data['year'] <= 2009)]\n",
        "filtered_data = filtered_data[filtered_data['fall'].isin(['Fell', 'Found'])]\n",
        "\n",
        "pivotTable = pd.pivot_table(\n",
        "    filtered_data,\n",
        "    values='mass (g)',\n",
        "    index='year',\n",
        "    columns='fall',\n",
        "    aggfunc=['count', lambda x: x.quantile(0.95)]\n",
        ")\n",
        "\n",
        "pivotTable.columns = ['_'.join(col).replace('<lambda>', '95th_percentile') for col in pivotTable.columns]\n",
        "\n",
        "print(pivotTable)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb832gIbQdkq",
        "outputId": "0027077e-791e-4f8e-df1b-dc4e618f4613"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3158055506.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data['year'] = pd.to_datetime(data['year'], errors='coerce').dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        count_Fell  count_Found  95th_percentile_Fell  95th_percentile_Found\n",
            "year                                                                        \n",
            "2005.0         NaN        874.0                   NaN                4500.00\n",
            "2006.0         5.0       2450.0               25008.0                1600.50\n",
            "2007.0         8.0       1181.0               89675.0                1126.90\n",
            "2008.0         9.0        948.0              106000.0                2274.80\n",
            "2009.0         5.0       1492.0                8333.4                1397.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = data.groupby('fall')[\"mass (g)\"].describe()\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckUXbHn7SEkb",
        "outputId": "5cb29cfe-dd62-48ca-bba1-1755c645909e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         count          mean            std  min     25%     50%      75%  \\\n",
            "fall                                                                        \n",
            "Fell    1075.0  47070.715023  717067.125826  0.1  686.00  2800.0  10450.0   \n",
            "Found  44510.0  12461.922983  571105.752311  0.0    6.94    30.5    178.0   \n",
            "\n",
            "              max  \n",
            "fall               \n",
            "Fell   23000000.0  \n",
            "Found  60000000.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise Part 5:"
      ],
      "metadata": {
        "id": "CummNvbGSODZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the taxi trip data in the 2019_Yellow_Taxi_Trip_Data.csv file, resample the data to an hourly frequency based on the dropoff time. Calculate the total trip_distance, fare_amount, tolls_amount, and tip_amount, then find the 5 hours with the most tips"
      ],
      "metadata": {
        "id": "899TcaajSJ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taxi = pd.read_csv('/content/drive/MyDrive/Foldah/2019_Yellow_Taxi_Trip_Data.csv')"
      ],
      "metadata": {
        "id": "14HC1jPCSPVX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taxi['tpep_dropoff_datetime'] = pd.to_datetime(taxi['tpep_dropoff_datetime'])\n",
        "taxi['hour'] = taxi['tpep_dropoff_datetime'].dt.floor('h')\n",
        "Hf = taxi.groupby('hour')[['trip_distance','fare_amount','tolls_amount','tip_amount']].sum()\n",
        "highest = Hf.sort_values('tip_amount', ascending=False).head(5)\n",
        "print(highest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cej_QqVYSfwZ",
        "outputId": "21951517-0fdb-4882-b155-6d33f1943f19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     trip_distance  fare_amount  tolls_amount  tip_amount\n",
            "hour                                                                     \n",
            "2019-10-23 16:00:00       10676.95     67797.76        699.04    12228.64\n",
            "2019-10-23 17:00:00       16052.83     70131.91       4044.04    12044.03\n",
            "2019-10-23 18:00:00        3104.56     11565.56       1454.67     1907.64\n",
            "2019-10-23 15:00:00          14.34       213.50          0.00       51.75\n",
            "2019-10-23 19:00:00          98.59       268.00         24.48       25.74\n"
          ]
        }
      ]
    }
  ]
}